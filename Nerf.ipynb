{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libaray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install point-cloud-utils\n",
    "!pip install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import point_cloud_utils as pcu\n",
    "import os, sys\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from skimage.metrics import structural_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialising the model and the get_rays function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def posenc(x):\n",
    "  rets = [x]\n",
    "  for i in range(L_embed):\n",
    "    for fn in [tf.sin, tf.cos]:\n",
    "      rets.append(fn(2.**i * x))\n",
    "  return tf.concat(rets, -1)\n",
    "\n",
    "L_embed = 6\n",
    "embed_fn = posenc\n",
    "\n",
    "def init_model(D=8, W=256):\n",
    "    relu = tf.keras.layers.ReLU()\n",
    "    dense = lambda W=W, act=relu : tf.keras.layers.Dense(W, activation=act)\n",
    "\n",
    "    inputs = tf.keras.Input(shape=(3 + 3*2*L_embed))\n",
    "    outputs = inputs\n",
    "    for i in range(D):\n",
    "        outputs = dense()(outputs)\n",
    "        if i%4==0 and i>0:\n",
    "            outputs = tf.concat([outputs, inputs], -1)\n",
    "    outputs = dense(4, act=None)(outputs)\n",
    "\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_rays(H, W, focal, c2w):\n",
    "    # Create a 2D rectangular grid for the rays corresponding to image dimensions\n",
    "    i, j = tf.meshgrid(tf.range(W, dtype=tf.float32), tf.range(H, dtype=tf.float32), indexing='xy')\n",
    "    # Normalize the x-axis coordinates\n",
    "    transformed_i = (i - W * 0.5) / focal\n",
    "    # Normalize the y-axis coordinates\n",
    "    transformed_j = -(j - H * 0.5) / focal\n",
    "    # z-axis coordinates\n",
    "    k = -tf.ones_like(i)\n",
    "    # Create the unit vectors corresponding to ray directions\n",
    "    dirs = tf.stack([transformed_i, transformed_j, k], -1)\n",
    "    # Compute Origins and Directions for each ray\n",
    "    rays_d = tf.reduce_sum(dirs[..., np.newaxis, :] * c2w[:3,:3], -1)\n",
    "    # rays_o = tf.broadcast_to(c2w[:3,-1], tf.shape(rays_d))\n",
    "    rays_o = tf.cast(tf.broadcast_to(c2w[:3,-1], tf.shape(rays_d)), dtype=tf.float32)\n",
    "    return rays_o, rays_d"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine SDF and NeRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_rays(network_fn, v, f, rays_o, rays_d, near, far, N_samples, rand=False):\n",
    "\n",
    "    def batchify(fn, chunk=1024*32):\n",
    "        return lambda inputs : tf.concat([fn(inputs[i:i+chunk]) for i in range(0, inputs.shape[0], chunk)], 0)\n",
    "\n",
    "    # Compute 3D query points\n",
    "    z_vals = tf.linspace(near, far, N_samples)\n",
    "    if rand:\n",
    "        z_vals += tf.random.uniform(list(rays_o.shape[:-1]) + [N_samples]) * (far - near) / N_samples\n",
    "    pts = rays_o[...,None,:] + rays_d[...,None,:] * z_vals[...,:,None]\n",
    "    pts_flat = tf.reshape(pts, [-1,3])\n",
    "\n",
    "\n",
    "    # Calculate 3D query points sdf value\n",
    "    pts_flat = pts_flat.numpy().astype(np.float32)\n",
    "    v = v.astype(np.float32, order='C').copy()\n",
    "    v_reshaped = v[:, :3]\n",
    "    sdfs, face_ids, barycentric_coords = pcu.signed_distance_to_mesh(pts_flat, v_reshaped, f)\n",
    "\n",
    "    pts_flat = embed_fn(pts_flat)\n",
    "    raw = batchify(network_fn)(pts_flat)\n",
    "    raw = tf.reshape(raw, list(pts.shape[:-1]) + [4])\n",
    "\n",
    "    # Compute opacities and colors use NeRF\n",
    "    sigma_a = tf.nn.relu(raw[...,3])\n",
    "    rgb = tf.math.sigmoid(raw[...,:3])\n",
    "\n",
    "    # Use SDF value to calculate opacities\n",
    "    sigma_a_sdf = tf.nn.sigmoid(-sdfs)\n",
    "    sigma_a_sdf = tf.reshape(sigma_a_sdf, list(pts.shape[:-1]))\n",
    "\n",
    "    # Combine SDF opacities and NeRF opacities\n",
    "    combined_sigma_a = (sigma_a + sigma_a_sdf) / 2\n",
    "\n",
    "    # Do volume rendering with combine opacities\n",
    "    dists = tf.concat([z_vals[..., 1:] - z_vals[..., :-1], tf.broadcast_to([1e10], z_vals[...,:1].shape)], -1)\n",
    "    alpha = 1.-tf.exp(-combined_sigma_a * dists)\n",
    "    weights = alpha * tf.math.cumprod(1.-alpha + 1e-10, -1, exclusive=True)\n",
    "\n",
    "    rgb_map = tf.reduce_sum(weights[...,None] * rgb, -2)\n",
    "    depth_map = tf.reduce_sum(weights * z_vals, -1)\n",
    "    acc_map = tf.reduce_sum(weights, -1)\n",
    "\n",
    "    return rgb_map, depth_map, acc_map"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Egypt model reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = 'DataSet/egypt_picture_data'\n",
    "\n",
    "file_names = os.listdir(folder_path)\n",
    "\n",
    "images_data = []\n",
    "for file_name in file_names:\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "    img = Image.open(file_path)\n",
    "\n",
    "    img = img.resize((200, 200))\n",
    "\n",
    "    img_array = np.array(img)\n",
    "\n",
    "    img_array = np.array(img) / 255.0\n",
    "\n",
    "    if len(img_array.shape) == 3 and img_array.shape[2] == 3:\n",
    "        images_data.append(img_array)\n",
    "\n",
    "images = np.array(images_data)\n",
    "\n",
    "poses_data = np.load('DataSet/camera_positions.npz')\n",
    "poses = poses_data['arr1']\n",
    "focal = 1.0\n",
    "focal = np.array(focal)\n",
    "v, f = pcu.load_mesh_vf(\"DataSet/egypt_model/baked_mesh.obj\")\n",
    "\n",
    "H, W = images.shape[1:3]\n",
    "print(images.shape, poses.shape, focal)\n",
    "\n",
    "testimg, testpose = images[99], poses[99]\n",
    "images = images[:90,...,:3]\n",
    "poses = poses[:90]\n",
    "\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "fig = plt.figure(figsize=(16, 16))\n",
    "grid = ImageGrid(fig, 111, nrows_ncols=(4, 4), axes_pad=0.1)\n",
    "random_images = images[np.random.choice(np.arange(images.shape[0]), 16)]\n",
    "for ax, image in zip(grid, random_images):\n",
    "    ax.imshow(image)\n",
    "plt.title(\"Sample Images from model data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = init_model()\n",
    "optimizer = tf.keras.optimizers.Adam(5e-4)\n",
    "\n",
    "# Output view, SSIM and Peak signal-to-noise ratio every 500 iterations\n",
    "N_samples = 64\n",
    "N_iters = 10000\n",
    "log_cosh_loss = []\n",
    "psnrs = []\n",
    "ssims = []\n",
    "timeList = []\n",
    "iternums = []\n",
    "i_plot = 500\n",
    "import time\n",
    "\n",
    "t = time.time()\n",
    "for i in range(N_iters+1):\n",
    "\n",
    "    img_i = np.random.randint(images.shape[0]) \n",
    "    target = images[img_i]\n",
    "    pose = poses[img_i]\n",
    "    rays_o, rays_d = get_rays(H, W, focal, pose)\n",
    "    with tf.GradientTape() as tape:\n",
    "        rgb, depth, acc = render_rays(model, v, f, rays_o, rays_d, near=0.1, far=10., N_samples=N_samples, rand=True)\n",
    "\n",
    "        # Calculate loss with Mean Squared Error\n",
    "        loss = tf.reduce_mean(tf.square(rgb - testimg))\n",
    "\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    log_cosh_loss.append(loss.numpy())\n",
    "    if i%i_plot==0:\n",
    "        time_per_iter = (time.time() - t) / i_plot\n",
    "        timeList.append(time_per_iter)\n",
    "        print(i, (time.time() - t) / i_plot, 'secs per iter')\n",
    "        t = time.time()\n",
    "\n",
    "        # Render the holdout view for logging\n",
    "        rays_o, rays_d = get_rays(H, W, focal, testpose)\n",
    "        rgb, depth, acc = render_rays(model, v, f, rays_o, rays_d, near=0.1, far=10., N_samples=N_samples, rand=True)\n",
    "        loss = tf.reduce_mean(tf.square(rgb - testimg))\n",
    "        # Calculate PSNR\n",
    "        psnr = -10. * tf.math.log(loss) / tf.math.log(10.)\n",
    "        # Calculate SSIM\n",
    "        testimg_float = tf.cast(testimg, tf.float32)\n",
    "        rgb_float = tf.cast(rgb, tf.float32)\n",
    "        ssim_value = tf.image.ssim(testimg_float, rgb_float, max_val = 1.0)\n",
    "\n",
    "        psnrs.append(psnr.numpy())\n",
    "        ssims.append(ssim_value.numpy())\n",
    "        iternums.append(i)\n",
    "\n",
    "        plt.figure(figsize=(10,4))\n",
    "        plt.subplot(121)\n",
    "        plt.imshow(rgb)\n",
    "        plt.title(f'RGB image, Iteration: {i}')\n",
    "        egypt_rgb_image = 'egypt_rgb_image'\n",
    "        if not os.path.exists(egypt_rgb_image):\n",
    "            os.makedirs(egypt_rgb_image)\n",
    "        output_path = os.path.join(egypt_rgb_image, f'{i}-rgb_image.png')\n",
    "        plt.savefig(output_path)\n",
    "        plt.close()\n",
    "        \n",
    "        plt.figure(figsize=(10,4))\n",
    "        plt.subplot(122)\n",
    "        plt.plot(iternums, ssims)\n",
    "        plt.title('SSIM')\n",
    "        egypt_ssim_image = 'egypt_ssim_image'\n",
    "        if not os.path.exists(egypt_ssim_image):\n",
    "            os.makedirs(egypt_ssim_image)\n",
    "        output_path = os.path.join(egypt_ssim_image, f'{i}-ssim_image.png')\n",
    "        plt.savefig(output_path)\n",
    "        plt.close()\n",
    "\n",
    "        plt.figure(figsize=(10,4))\n",
    "        plt.subplot(122)\n",
    "        plt.plot(iternums, psnrs)\n",
    "        plt.title('PSNR')\n",
    "        egypt_psnr_image = 'egypt_psnr_image'\n",
    "        if not os.path.exists(egypt_psnr_image):\n",
    "            os.makedirs(egypt_psnr_image)\n",
    "        output_path = os.path.join(egypt_psnr_image, f'{i}-psnr_image.png')\n",
    "        plt.savefig(output_path)\n",
    "        plt.close()\n",
    "\n",
    "# Store PSNR data\n",
    "iteration_number = list(range(0, 10000, 500))\n",
    "psnr_file_path = 'egypt_PSNR_Data.txt'\n",
    "\n",
    "if not os.path.exists(psnr_file_path):\n",
    "    with open(psnr_file_path, 'w') as file:\n",
    "        file.write(\"Iteration Number\\tTime per iter\\tPSNR\\n\")\n",
    "\n",
    "with open(psnr_file_path, 'a') as file:\n",
    "    for col, val_a, val_b in zip(iteration_number, timeList, psnrs):\n",
    "        file.write(f\"{col}\\t{val_a}\\t{val_b}\\n\")\n",
    "print(f\"PSNR data written to {psnr_file_path}\")\n",
    "\n",
    "# Store SSIM data\n",
    "ssim_file_path = 'egypt_SSIM_data.txt'\n",
    "\n",
    "if not os.path.exists(ssim_file_path):\n",
    "    with open(ssim_file_path, 'w') as file:\n",
    "        file.write(\"Iteration Number\\tTime per iter\\tSSIM\\n\")\n",
    "\n",
    "with open(ssim_file_path, 'a') as file:\n",
    "    for col, val_a, val_b in zip(iteration_number, timeList, ssims):\n",
    "        file.write(f\"{col}\\t{val_a}\\t{val_b}\\n\")\n",
    "print(f\"SSIM data written to {ssim_file_path}\")\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plane model reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = 'DataSet/model_picture_data'\n",
    "\n",
    "file_names = os.listdir(folder_path)\n",
    "\n",
    "images_data = []\n",
    "for file_name in file_names:\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "    img = Image.open(file_path)\n",
    "\n",
    "    img = img.resize((200,200))\n",
    "\n",
    "    img_array = np.array(img)\n",
    "\n",
    "    img_array = np.array(img) / 255.0\n",
    "\n",
    "    if len(img_array.shape) == 3 and img_array.shape[2] == 3:\n",
    "        images_data.append(img_array)\n",
    "\n",
    "images = np.array(images_data)\n",
    "print(tf.shape(images))\n",
    "\n",
    "poses_data = np.load('DataSet/camera_positions.npz')\n",
    "poses = poses_data['arr1']\n",
    "focal = 1.0\n",
    "focal = np.array(focal)\n",
    "v, f = pcu.load_mesh_vf(\"DataSet/models/model_normalized.obj\")\n",
    "\n",
    "H, W = images.shape[1:3]\n",
    "print(images.shape, poses.shape, focal)\n",
    "\n",
    "testimg, testpose = images[99], poses[99]\n",
    "images = images[:90,...,:3]\n",
    "poses = poses[:90]\n",
    "\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "fig = plt.figure(figsize=(16, 16))\n",
    "grid = ImageGrid(fig, 111, nrows_ncols=(4, 4), axes_pad=0.1)\n",
    "random_images = images[np.random.choice(np.arange(images.shape[0]), 16)]\n",
    "for ax, image in zip(grid, random_images):\n",
    "    ax.imshow(image)\n",
    "plt.title(\"Sample Images from model data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = init_model()\n",
    "optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "\n",
    "# Output view, SSIM and Peak signal-to-noise ratio every 500 iterations\n",
    "N_samples = 64\n",
    "N_iters = 10000\n",
    "log_cosh_loss = []\n",
    "psnrs = []\n",
    "ssims = []\n",
    "timeList = []\n",
    "iternums = []\n",
    "i_plot = 500\n",
    "import time\n",
    "\n",
    "t = time.time()\n",
    "for i in range(N_iters+1):\n",
    "\n",
    "    img_i = np.random.randint(images.shape[0]) \n",
    "    target = images[img_i]\n",
    "    pose = poses[img_i]\n",
    "    rays_o, rays_d = get_rays(H, W, focal, pose)\n",
    "    with tf.GradientTape() as tape:\n",
    "        rgb, depth, acc = render_rays(model, v, f, rays_o, rays_d, near=0.1, far=10., N_samples=N_samples, rand=True)\n",
    "\n",
    "        # Calculate loss with Mean Squared Error\n",
    "        loss = tf.reduce_mean(tf.square(rgb - testimg))\n",
    "\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    log_cosh_loss.append(loss.numpy())\n",
    "    if i%i_plot==0:\n",
    "        time_per_iter = (time.time() - t) / i_plot\n",
    "        timeList.append(time_per_iter)\n",
    "        print(i, (time.time() - t) / i_plot, 'secs per iter')\n",
    "        t = time.time()\n",
    "\n",
    "        # Render the holdout view for logging\n",
    "        rays_o, rays_d = get_rays(H, W, focal, testpose)\n",
    "        rgb, depth, acc = render_rays(model, v, f, rays_o, rays_d, near=0.1, far=10., N_samples=N_samples, rand=True)\n",
    "        loss = tf.reduce_mean(tf.square(rgb - testimg))\n",
    "        # Calculate PSNR\n",
    "        psnr = -10. * tf.math.log(loss) / tf.math.log(10.)\n",
    "        # Calculate SSIM\n",
    "        testimg_float = tf.cast(testimg, tf.float32)\n",
    "        rgb_float = tf.cast(rgb, tf.float32)\n",
    "        ssim_value = tf.image.ssim(testimg_float, rgb_float, max_val = 1.0)\n",
    "\n",
    "        psnrs.append(psnr.numpy())\n",
    "        ssims.append(ssim_value.numpy())\n",
    "        iternums.append(i)\n",
    "\n",
    "        plt.figure(figsize=(10,4))\n",
    "        plt.subplot(121)\n",
    "        plt.imshow(rgb)\n",
    "        plt.title(f'RGB image, Iteration: {i}')\n",
    "        plane_rgb_image = 'plane_rgb_image'\n",
    "        if not os.path.exists(plane_rgb_image):\n",
    "            os.makedirs(plane_rgb_image)\n",
    "        output_path = os.path.join(plane_rgb_image, f'{i}-rgb_image.png')\n",
    "        plt.savefig(output_path)\n",
    "        plt.close()\n",
    "        \n",
    "        plt.figure(figsize=(10,4))\n",
    "        plt.subplot(122)\n",
    "        plt.plot(iternums, ssims)\n",
    "        plt.title('SSIM')\n",
    "        plane_ssim_image = 'plane_ssim_image'\n",
    "        if not os.path.exists(plane_ssim_image):\n",
    "            os.makedirs(plane_ssim_image)\n",
    "        output_path = os.path.join(plane_ssim_image, f'{i}-ssim_image.png')\n",
    "        plt.savefig(output_path)\n",
    "        plt.close()\n",
    "\n",
    "        plt.figure(figsize=(10,4))\n",
    "        plt.subplot(122)\n",
    "        plt.plot(iternums, psnrs)\n",
    "        plt.title('PSNR')\n",
    "        plane_psnr_image = 'plane_psnr_image'\n",
    "        if not os.path.exists(plane_psnr_image):\n",
    "            os.makedirs(plane_psnr_image)\n",
    "        output_path = os.path.join(plane_psnr_image, f'{i}-psnr_image.png')\n",
    "        plt.savefig(output_path)\n",
    "        plt.close()\n",
    "\n",
    "# Store PSNR data\n",
    "iteration_number = list(range(0, 10000, 500))\n",
    "psnr_file_path = 'plane_PSNR_Data.txt'\n",
    "\n",
    "if not os.path.exists(psnr_file_path):\n",
    "    with open(psnr_file_path, 'w') as file:\n",
    "        file.write(\"Iteration Number\\tTime per iter\\tPSNR\\n\")\n",
    "\n",
    "with open(psnr_file_path, 'a') as file:\n",
    "    for col, val_a, val_b in zip(iteration_number, timeList, psnrs):\n",
    "        file.write(f\"{col}\\t{val_a}\\t{val_b}\\n\")\n",
    "print(f\"PSNR data written to {psnr_file_path}\")\n",
    "\n",
    "# Store SSIM data\n",
    "ssim_file_path = 'plane_SSIM_data.txt'\n",
    "\n",
    "if not os.path.exists(ssim_file_path):\n",
    "    with open(ssim_file_path, 'w') as file:\n",
    "        file.write(\"Iteration Number\\tTime per iter\\tSSIM\\n\")\n",
    "\n",
    "with open(ssim_file_path, 'a') as file:\n",
    "    for col, val_a, val_b in zip(iteration_number, timeList, ssims):\n",
    "        file.write(f\"{col}\\t{val_a}\\t{val_b}\\n\")\n",
    "print(f\"SSIM data written to {ssim_file_path}\")\n",
    "\n",
    "\n",
    "print('Done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3Drecon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
