{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_16\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_17 (InputLayer)          [(None, 39)]         0           []                               \n",
      "                                                                                                  \n",
      " dense_144 (Dense)              (None, 256)          10240       ['input_17[0][0]']               \n",
      "                                                                                                  \n",
      " dense_145 (Dense)              (None, 256)          65792       ['dense_144[0][0]']              \n",
      "                                                                                                  \n",
      " dense_146 (Dense)              (None, 256)          65792       ['dense_145[0][0]']              \n",
      "                                                                                                  \n",
      " dense_147 (Dense)              (None, 256)          65792       ['dense_146[0][0]']              \n",
      "                                                                                                  \n",
      " dense_148 (Dense)              (None, 256)          65792       ['dense_147[0][0]']              \n",
      "                                                                                                  \n",
      " tf.concat_16 (TFOpLambda)      (None, 295)          0           ['dense_148[0][0]',              \n",
      "                                                                  'input_17[0][0]']               \n",
      "                                                                                                  \n",
      " dense_149 (Dense)              (None, 256)          75776       ['tf.concat_16[0][0]']           \n",
      "                                                                                                  \n",
      " dense_150 (Dense)              (None, 256)          65792       ['dense_149[0][0]']              \n",
      "                                                                                                  \n",
      " dense_151 (Dense)              (None, 256)          65792       ['dense_150[0][0]']              \n",
      "                                                                                                  \n",
      " dense_152 (Dense)              (None, 4)            1028        ['dense_151[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 481,796\n",
      "Trainable params: 481,796\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "L_embed = 6\n",
    "\n",
    "relu = tf.keras.layers.ReLU()    \n",
    "dense = lambda W=256, act=relu : tf.keras.layers.Dense(W, activation=act)\n",
    "\n",
    "inputs = tf.keras.Input(shape=(3 + 3*2*L_embed))\n",
    "# print(inputs) \n",
    "outputs = inputs\n",
    "for i in range(8):\n",
    "    outputs = dense()(outputs)\n",
    "    # print(outputs)\n",
    "    if i%4==0 and i>0:\n",
    "        outputs = tf.concat([outputs, inputs], -1)\n",
    "        # print('xx', outputs)\n",
    "outputs = dense(4, act=None)(outputs)\n",
    "# print(outputs)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: (_Arg): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "_EagerConst: (_EagerConst): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "output_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "a: (_Arg): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "b: (_Arg): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "MatMul: (MatMul): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "product_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op MatMul in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "tf.Tensor(\n",
      "[[22. 28.]\n",
      " [49. 64.]], shape=(2, 2), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-17 03:03:51.807732: I tensorflow/core/common_runtime/placer.cc:114] input: (_Arg): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "2023-07-17 03:03:51.807923: I tensorflow/core/common_runtime/placer.cc:114] _EagerConst: (_EagerConst): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "2023-07-17 03:03:51.807930: I tensorflow/core/common_runtime/placer.cc:114] output_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "2023-07-17 03:03:51.833456: I tensorflow/core/common_runtime/placer.cc:114] a: (_Arg): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "2023-07-17 03:03:51.833471: I tensorflow/core/common_runtime/placer.cc:114] b: (_Arg): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "2023-07-17 03:03:51.833478: I tensorflow/core/common_runtime/placer.cc:114] MatMul: (MatMul): /job:localhost/replica:0/task:0/device:CPU:0\n",
      "2023-07-17 03:03:51.833482: I tensorflow/core/common_runtime/placer.cc:114] product_RetVal: (_Retval): /job:localhost/replica:0/task:0/device:CPU:0\n"
     ]
    }
   ],
   "source": [
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "# Create some tensors\n",
    "a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
    "c = tf.matmul(a, b)\n",
    "\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op MatMul in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "tf.Tensor(\n",
      "[[22. 28.]\n",
      " [49. 64.]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "# Place tensors on the CPU\n",
    "with tf.device('/CPU:0'):\n",
    "  a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "  b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
    "\n",
    "# Run on the GPU\n",
    "c = tf.matmul(a, b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib \n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'interactive' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 54\u001b[0m\n\u001b[1;32m     41\u001b[0m sldr \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m v, mi, ma: widgets\u001b[39m.\u001b[39mFloatSlider(\n\u001b[1;32m     42\u001b[0m     value\u001b[39m=\u001b[39mv,\n\u001b[1;32m     43\u001b[0m     \u001b[39mmin\u001b[39m\u001b[39m=\u001b[39mmi,\n\u001b[1;32m     44\u001b[0m     \u001b[39mmax\u001b[39m\u001b[39m=\u001b[39mma,\n\u001b[1;32m     45\u001b[0m     step\u001b[39m=\u001b[39m\u001b[39m.01\u001b[39m,\n\u001b[1;32m     46\u001b[0m )\n\u001b[1;32m     48\u001b[0m names \u001b[39m=\u001b[39m [\n\u001b[1;32m     49\u001b[0m     [\u001b[39m'\u001b[39m\u001b[39mtheta\u001b[39m\u001b[39m'\u001b[39m, [\u001b[39m100.\u001b[39m, \u001b[39m0.\u001b[39m, \u001b[39m360\u001b[39m]],\n\u001b[1;32m     50\u001b[0m     [\u001b[39m'\u001b[39m\u001b[39mphi\u001b[39m\u001b[39m'\u001b[39m, [\u001b[39m-\u001b[39m\u001b[39m30.\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m90\u001b[39m, \u001b[39m0\u001b[39m]],\n\u001b[1;32m     51\u001b[0m     [\u001b[39m'\u001b[39m\u001b[39mradius\u001b[39m\u001b[39m'\u001b[39m, [\u001b[39m4.\u001b[39m, \u001b[39m3.\u001b[39m, \u001b[39m5.\u001b[39m]],\n\u001b[1;32m     52\u001b[0m ]\n\u001b[0;32m---> 54\u001b[0m interactive_plot \u001b[39m=\u001b[39m interactive(f, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m{s[\u001b[39m0\u001b[39m] : sldr(\u001b[39m*\u001b[39ms[\u001b[39m1\u001b[39m]) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m names})\n\u001b[1;32m     55\u001b[0m output \u001b[39m=\u001b[39m interactive_plot\u001b[39m.\u001b[39mchildren[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m     56\u001b[0m output\u001b[39m.\u001b[39mlayout\u001b[39m.\u001b[39mheight \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m350px\u001b[39m\u001b[39m'\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'interactive' is not defined"
     ]
    }
   ],
   "source": [
    "trans_t = lambda t : tf.convert_to_tensor([\n",
    "    [1,0,0,0],\n",
    "    [0,1,0,0],\n",
    "    [0,0,1,t],\n",
    "    [0,0,0,1],\n",
    "], dtype=tf.float32)\n",
    "\n",
    "rot_phi = lambda phi : tf.convert_to_tensor([\n",
    "    [1,0,0,0],\n",
    "    [0,tf.cos(phi),-tf.sin(phi),0],\n",
    "    [0,tf.sin(phi), tf.cos(phi),0],\n",
    "    [0,0,0,1],\n",
    "], dtype=tf.float32)\n",
    "\n",
    "rot_theta = lambda th : tf.convert_to_tensor([\n",
    "    [tf.cos(th),0,-tf.sin(th),0],\n",
    "    [0,1,0,0],\n",
    "    [tf.sin(th),0, tf.cos(th),0],\n",
    "    [0,0,0,1],\n",
    "], dtype=tf.float32)\n",
    "\n",
    "def pose_spherical(theta, phi, radius):\n",
    "    c2w = trans_t(radius)\n",
    "    c2w = rot_phi(phi/180.*np.pi) @ c2w\n",
    "    c2w = rot_theta(theta/180.*np.pi) @ c2w\n",
    "    c2w = np.array([[-1,0,0,0],[0,0,1,0],[0,1,0,0],[0,0,0,1]]) @ c2w\n",
    "    return c2w\n",
    "\n",
    "\n",
    "def f(**kwargs):\n",
    "    c2w = pose_spherical(**kwargs)\n",
    "    rays_o, rays_d = get_rays(H, W, focal, c2w[:3,:4])\n",
    "    rgb, depth, acc = render_rays(model, rays_o, rays_d, near=2., far=6., N_samples=N_samples)\n",
    "    img = np.clip(rgb,0,1)\n",
    "    \n",
    "    plt.figure(2, figsize=(20,6))\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "sldr = lambda v, mi, ma: widgets.FloatSlider(\n",
    "    value=v,\n",
    "    min=mi,\n",
    "    max=ma,\n",
    "    step=.01,\n",
    ")\n",
    "\n",
    "names = [\n",
    "    ['theta', [100., 0., 360]],\n",
    "    ['phi', [-30., -90, 0]],\n",
    "    ['radius', [4., 3., 5.]],\n",
    "]\n",
    "\n",
    "interactive_plot = interactive(f, **{s[0] : sldr(*s[1]) for s in names})\n",
    "output = interactive_plot.children[-1]\n",
    "output.layout.height = '350px'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea6c47a3709a48ed9f5f3f40547de693",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'pose_spherical' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m th \u001b[39min\u001b[39;00m tqdm(np\u001b[39m.\u001b[39mlinspace(\u001b[39m0.\u001b[39m, \u001b[39m360.\u001b[39m, \u001b[39m120\u001b[39m, endpoint\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)):\n\u001b[0;32m----> 4\u001b[0m     c2w \u001b[39m=\u001b[39m pose_spherical(th, \u001b[39m-\u001b[39m\u001b[39m30.\u001b[39m, \u001b[39m4.\u001b[39m)\n\u001b[1;32m      5\u001b[0m     rays_o, rays_d \u001b[39m=\u001b[39m get_rays(H, W, focal, c2w[:\u001b[39m3\u001b[39m,:\u001b[39m4\u001b[39m])\n\u001b[1;32m      6\u001b[0m     rgb, depth, acc \u001b[39m=\u001b[39m render_rays(model, rays_o, rays_d, near\u001b[39m=\u001b[39m\u001b[39m2.\u001b[39m, far\u001b[39m=\u001b[39m\u001b[39m6.\u001b[39m, N_samples\u001b[39m=\u001b[39mN_samples)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pose_spherical' is not defined"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "def pose_spherical(theta, phi, radius):\n",
    "    c2w = trans_t(radius)\n",
    "    c2w = rot_phi(phi/180.*np.pi) @ c2w\n",
    "    c2w = rot_theta(theta/180.*np.pi) @ c2w\n",
    "    c2w = np.array([[-1,0,0,0],[0,0,1,0],[0,1,0,0],[0,0,0,1]]) @ c2w\n",
    "    return c2w\n",
    "\n",
    "for th in tqdm(np.linspace(0., 360., 120, endpoint=False)):\n",
    "    c2w = pose_spherical(th, -30., 4.)\n",
    "    rays_o, rays_d = get_rays(H, W, focal, c2w[:3,:4])\n",
    "    rgb, depth, acc = render_rays(model, rays_o, rays_d, near=2., far=6., N_samples=N_samples)\n",
    "    frames.append((255*np.clip(rgb,0,1)).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n",
      "\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m\n",
      "\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\n",
      "\u001b[0;32m----> 3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n",
      "\u001b[1;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msklearn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39msk\u001b[39;00m\n",
      "\u001b[1;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mscipy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39msp\u001b[39;00m\n",
      "\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import tensorflow.keras\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import scipy as sp\n",
    "import tensorflow as tf\n",
    "import platform\n",
    "print(f\"Python Platform: {platform.platform()}\")\n",
    "print(f\"Tensor Flow Version: {tf.__version__}\")\n",
    "print(f\"Keras Version: {tensorflow.keras.__version__}\")\n",
    "print()\n",
    "print(f\"Python {sys.version}\")\n",
    "print(f\"Pandas {pd.__version__}\")\n",
    "print(f\"Scikit-Learn {sk.__version__}\")\n",
    "print(f\"SciPy {sp.__version__}\")\n",
    "gpu = len(tf.config.list_physical_devices('GPU'))>0\n",
    "print(\"GPU is\", \"available\" if gpu else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A local file was found, but it seems to be incomplete or outdated because the auto file hash does not match the original value of 85cd44d02ba6437773c5bbd22e183051d648de2e7d6b014e1ef29b855ba677a7 so we will re-download the data.\n",
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
      "164536320/169001437 [============================>.] - ETA: 0s"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Incomplete or corrupted file detected. The auto file hash does not match the provided value of 85cd44d02ba6437773c5bbd22e183051d648de2e7d6b014e1ef29b855ba677a7.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m\n",
      "\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n",
      "\u001b[1;32m      3\u001b[0m cifar \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mdatasets\u001b[39m.\u001b[39mcifar100\n",
      "\u001b[0;32m----> 4\u001b[0m (x_train, y_train), (x_test, y_test) \u001b[39m=\u001b[39m cifar\u001b[39m.\u001b[39;49mload_data()\n",
      "\u001b[1;32m      5\u001b[0m model \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mapplications\u001b[39m.\u001b[39mResNet50(\n",
      "\u001b[1;32m      6\u001b[0m     include_top\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n",
      "\u001b[1;32m      7\u001b[0m     weights\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n",
      "\u001b[1;32m      8\u001b[0m     input_shape\u001b[39m=\u001b[39m(\u001b[39m32\u001b[39m, \u001b[39m32\u001b[39m, \u001b[39m3\u001b[39m),\n",
      "\u001b[1;32m      9\u001b[0m     classes\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m,)\n",
      "\u001b[1;32m     11\u001b[0m loss_fn \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlosses\u001b[39m.\u001b[39mSparseCategoricalCrossentropy(from_logits\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/3D-GPU/lib/python3.11/site-packages/keras/datasets/cifar100.py:78\u001b[0m, in \u001b[0;36mload_data\u001b[0;34m(label_mode)\u001b[0m\n",
      "\u001b[1;32m     76\u001b[0m dirname \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcifar-100-python\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[1;32m     77\u001b[0m origin \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mhttps://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[0;32m---> 78\u001b[0m path \u001b[39m=\u001b[39m get_file(\n",
      "\u001b[1;32m     79\u001b[0m     dirname,\n",
      "\u001b[1;32m     80\u001b[0m     origin\u001b[39m=\u001b[39;49morigin,\n",
      "\u001b[1;32m     81\u001b[0m     untar\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n",
      "\u001b[1;32m     82\u001b[0m     file_hash\u001b[39m=\u001b[39;49m(  \u001b[39m# noqa: E501\u001b[39;49;00m\n",
      "\u001b[1;32m     83\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39m85cd44d02ba6437773c5bbd22e183051d648de2e7d6b014e1ef29b855ba677a7\u001b[39;49m\u001b[39m\"\u001b[39;49m\n",
      "\u001b[1;32m     84\u001b[0m     ),\n",
      "\u001b[1;32m     85\u001b[0m )\n",
      "\u001b[1;32m     87\u001b[0m fpath \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(path, \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32m     88\u001b[0m x_train, y_train \u001b[39m=\u001b[39m load_batch(fpath, label_key\u001b[39m=\u001b[39mlabel_mode \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m_labels\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/3D-GPU/lib/python3.11/site-packages/keras/utils/data_utils.py:361\u001b[0m, in \u001b[0;36mget_file\u001b[0;34m(fname, origin, untar, md5_hash, file_hash, cache_subdir, hash_algorithm, extract, archive_format, cache_dir)\u001b[0m\n",
      "\u001b[1;32m    359\u001b[0m     \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(fpath) \u001b[39mand\u001b[39;00m file_hash \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;32m    360\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m validate_file(fpath, file_hash, algorithm\u001b[39m=\u001b[39mhash_algorithm):\n",
      "\u001b[0;32m--> 361\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n",
      "\u001b[1;32m    362\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mIncomplete or corrupted file detected. \u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[1;32m    363\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe \u001b[39m\u001b[39m{\u001b[39;00mhash_algorithm\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[1;32m    364\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mfile hash does not match the provided value \u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[1;32m    365\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mof \u001b[39m\u001b[39m{\u001b[39;00mfile_hash\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[1;32m    366\u001b[0m             )\n",
      "\u001b[1;32m    368\u001b[0m \u001b[39mif\u001b[39;00m untar:\n",
      "\u001b[1;32m    369\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(untar_fpath):\n",
      "\n",
      "\u001b[0;31mValueError\u001b[0m: Incomplete or corrupted file detected. The auto file hash does not match the provided value of 85cd44d02ba6437773c5bbd22e183051d648de2e7d6b014e1ef29b855ba677a7."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "cifar = tf.keras.datasets.cifar100\n",
    "(x_train, y_train), (x_test, y_test) = cifar.load_data()\n",
    "model = tf.keras.applications.ResNet50(\n",
    "    include_top=True,\n",
    "    weights=None,\n",
    "    input_shape=(32, 32, 3),\n",
    "    classes=100,)\n",
    "\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "model.compile(optimizer=\"adam\", loss=loss_fn, metrics=[\"accuracy\"])\n",
    "model.fit(x_train, y_train, epochs=5, batch_size=64)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3Drecon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
